{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Project 3 - Classification\n",
    "Welcome to the third project of Data 8!  You will build a classifier that guesses whether a song is hip-hop or country, using only the numbers of times words appear in the song's lyrics.  By the end of the project, you should know how to:\n",
    "\n",
    "1. Build a k-nearest-neighbors classifier.\n",
    "2. Test a classifier on data.\n",
    "\n",
    "### Logistics\n",
    "\n",
    "\n",
    "**Deadline.** This project is due at 11:59pm on Thursday 4/27. You can earn an early submission bonus point by submitting your completed project by Wednesday 4/26. Late submissions will be accepted until Tuesday 5/2, but a 10% late penalty will be applied for each day late. It's **much** better to be early than late, so start working now.\n",
    "\n",
    "**Checkpoint.** For full credit, you must also **complete Part 1 of the project (out of 4) and submit them by 11:59pm on Friday 4/21**. You will have some lab time to work on these questions, but we recommend that you start the project before lab and leave time to finish the checkpoint afterward.\n",
    "\n",
    "**Partners.** You may work with one other partner. It's best to work with someone in your lab. Only one of you is required to submit the project. On [okpy.org](http://okpy.org), the person who submits should also designate their partner so that both of you receive credit.\n",
    "\n",
    "**Rules.** Don't share your code with anybody but your partner. You are welcome to discuss questions with other students, but don't share the answers. The experience of solving the problems in this project will prepare you for exams (and life). If someone asks you for the answer, resist! Instead, you can demonstrate how you would solve a similar problem.\n",
    "\n",
    "**Support.** You are not alone! Come to office hours, post on Piazza, and talk to your classmates. If you want to ask about the details of your solution to a problem, make a private Piazza post and the staff will respond. If you're ever feeling overwhelmed or don't know how to make progress, email your TA or tutor for help. You can find contact information for the staff on the [course website](http://data8.org/sp17/staff.html).\n",
    "\n",
    "**Tests.** Passing the tests for a question **does not** mean that you answered the question correctly. Tests usually only check that your table has the correct column labels. However, more tests will be applied to verify the correctness of your submission in order to assign your final score, so be careful and check your work!\n",
    "\n",
    "**Advice.** Develop your answers incrementally. To perform a complicated table manipulation, break it up into steps, perform each step on a different line, give a new name to each result, and check that each intermediate result is what you expect. You can add any additional names or functions you want to the provided cells. \n",
    "\n",
    "To get started, load `datascience`, `numpy`, `plots`, and `ok`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": true,
    "editable": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/ipykernel_launcher.py:9: MatplotlibDeprecationWarning: The 'warn' parameter of use() is deprecated since Matplotlib 3.1 and will be removed in 3.3.  If any parameter follows 'warn', they should be pass as keyword, not positionally.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from datascience import *\n",
    "\n",
    "# These lines set up the plotting functionality and formatting.\n",
    "import matplotlib\n",
    "matplotlib.use('Agg', warn=False)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# These lines load the tests.\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('project3.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. The Dataset\n",
    "\n",
    "Our dataset is a table of songs, each with a name, an artist, and a genre.  We'll be trying to predict each song's genre.\n",
    "\n",
    "The only attributes we will use to predict the genre of a song are its lyrics. In particular, we have a list of just under 5,000 words that might occur in a song.  For each song, our dataset tells us the frequency with which each of these words occurs in that song. All words have been converted to lowercase.\n",
    "\n",
    "Run the cell below to read the `lyrics` table. **It may take up to a minute to load.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Title</th> <th>Artist</th> <th>Genre</th> <th>i</th> <th>the</th> <th>you</th> <th>like</th> <th>love</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>In Your Eyes</td> <td>Alison Krauss</td> <td>Country</td> <td>0.107143</td> <td>0   </td> <td>0.0297619</td> <td>0.0119048</td> <td>0.0595238</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Title        | Artist        | Genre   | i        | the  | you       | like      | love\n",
       "In Your Eyes | Alison Krauss | Country | 0.107143 | 0    | 0.0297619 | 0.0119048 | 0.0595238"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = Table.read_table('lyrics.csv')\n",
    "lyrics.where(\"Title\", \"In Your Eyes\").select(0, 1, 2, 3, 4, 5, \"like\", \"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That cell prints a few columns of the row for the country song [\"In Your Eyes\" by Alison Krauss](http://www.azlyrics.com/lyrics/alisonkrauss/inyoureyes.html).  The song contains 168 words. The word \"like\" appears twice:  $\\frac{2}{168} \\approx 0.0119$ of the words in the song. The word \"love\" appears 10 times: $\\frac{10}{168} \\approx 0.0595$ of the words. The word \"the\" doesn't appear at all.\n",
    "\n",
    "Our dataset doesn't contain all information about a song.  For example, it doesn't describe the order of words in the song, let alone the melody, instruments, or rhythm. Nonetheless, you may find that word frequencies alone are sufficient to build an accurate genre classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "All titles are unique. The `row_for_title` function provides fast access to the one row for each title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "title_index = lyrics.index_by('Title')\n",
    "def row_for_title(title):\n",
    "    \"\"\"Return the row for a title, similar to the following expression (but faster)\n",
    "    \n",
    "    lyrics.where('Title', title).row(0)\n",
    "    \"\"\"\n",
    "    return title_index.get(title)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For example, the fastest way to find the frequency of \"love\" in the song *In Your Eyes* is to access the `'love'` item from its row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05952381"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_for_title('In Your Eyes').item('love')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 1.1\n",
    "Set `expected_row_sum` to the number that you expect will result from summing all proportions in each row, excluding the first three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000420000001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set row_sum to a number that's the (approximate) sum of each row of word proportions.\n",
    "expected_row_sum = lyrics.drop([0,1,2]).apply(sum).item(0)\n",
    "expected_row_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-38b23d812c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q1_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/client/api/notebook.py\u001b[0m in \u001b[0;36mgrade\u001b[0;34m(self, question, global_env)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# inspect trick to pass in its parents' global env.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mglobal_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;31m# We display the output if we're in IPython.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# This keeps backwards compatibility with okpy's grade method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/okgrade/grader.py\u001b[0m in \u001b[0;36mgrade\u001b[0;34m(test_file_path, global_env)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mTestResult\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_ok_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mglobal_env\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Get the global env of our callers - one level below us in the stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/okgrade/grader.py\u001b[0m in \u001b[0;36mparse_ok_test\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Do not support point values other than 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtest_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtest_suite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'suites'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_ = ok.grade(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Run the cell below to generate a histogram of the actual row sums. It should confirm your answer above, perhaps with a small amount of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to display a histogram of the sums of proportions in each row.\n",
    "# This computation might take up to a minute; you can skip it if it's too slow.\n",
    "Table().with_column('sums', lyrics.drop([0, 1, 2]).apply(sum)).hist(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This dataset was extracted from the [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/). Specifically, we are using the complementary datasets from [musiXmatch](http://labrosa.ee.columbia.edu/millionsong/musixmatch) and [Last.fm](http://labrosa.ee.columbia.edu/millionsong/lastfm). \n",
    "\n",
    "The counts of common words in the lyrics for all of these songs are provided by the musiXmatch dataset (called a bag-of-words format). We converted the words to lowercase, removed the naughty ones, and converted the counts to frequencies.\n",
    "\n",
    "The Last.fm dataset contains multiple tags for each song in the Million Song Dataset. Some of the tags are genre-related, such as \"pop\", \"rock\", \"classic\", etc.  To construct the `Genre` column, we first extracted songs with Last.fm tags that included the words \"country\", or both \"hip\" and \"hop\". These songs were then cross-referenced with the musiXmatch dataset, and only songs with musixMatch lyrics were placed into our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with frequencies: 4817\n",
      "Songs with genres: 1721\n"
     ]
    }
   ],
   "source": [
    "print('Words with frequencies:', lyrics.drop('Title', 'Artist', 'Genre').num_columns)\n",
    "print('Songs with genres:', lyrics.num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.1. Word Stemming\n",
    "The columns other than Title, Artist, and Genre in the `lyrics` table are all words that appear in some of the songs in our dataset.  Some of those names have been *stemmed*, or abbreviated heuristically, in an attempt to make different [inflected](https://en.wikipedia.org/wiki/Inflection) forms of the same base word into the same string.  For example, the column \"manag\" is the sum of proportions of the words \"manage\", \"manager\", \"managed\", and \"managerial\" (and perhaps others) in each song.  \n",
    "\n",
    "Stemming makes it a little tricky to search for the words you want to use, so we have provided another table that will let you see examples of unstemmed versions of each stemmed word.  Run the code below to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Stem</th> <th>Word</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>devant</td> <td>devant     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>devast</td> <td>devastation</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>devil </td> <td>devil      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>devot </td> <td>devotion   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>devour</td> <td>devour     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dew   </td> <td>dew        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>di    </td> <td>di         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dia   </td> <td>dia        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>diablo</td> <td>diablo     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dial  </td> <td>dial       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Stem   | Word\n",
       "devant | devant\n",
       "devast | devastation\n",
       "devil  | devil\n",
       "devot  | devotion\n",
       "devour | devour\n",
       "dew    | dew\n",
       "di     | di\n",
       "dia    | dia\n",
       "diablo | diablo\n",
       "dial   | dial"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just run this cell.\n",
    "vocab_mapping = Table.read_table('mxm_reverse_mapping_safe.csv')\n",
    "stemmed = np.take(lyrics.labels, np.arange(3, len(lyrics.labels)))\n",
    "vocab_table = Table().with_column('Stem', stemmed).join('Stem', vocab_mapping)\n",
    "vocab_table.take(np.arange(1100, 1110))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 1.1.1\n",
    "Assign `unchanged` to the **percentage** of words in `vocab_table` that are the same as their stemmed form (such as \"devour\" above).\n",
    "\n",
    "*Hint:* Try using `where` and comparing the number of rows in a table of only unchanged vocabulary with the number of rows in `vocab_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/datascience/predicates.py:261: SyntaxWarning: Do not pass an array or list to a predicate.                 If you are trying to find rows where two columns are the                 same, use table.where('c', are.equal_to, table.column('d'))                instead of table.where('c', are.equal_to(table.column('d'))).\n",
      "  SyntaxWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72 percent are unchanged\n"
     ]
    }
   ],
   "source": [
    "percent_unchanged = vocab_table.where(0, vocab_table.column(1)).num_rows / vocab_table.num_rows\n",
    "print(round(percent_unchanged, 2), 'percent are unchanged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ecd720bef855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q1_1_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/client/api/notebook.py\u001b[0m in \u001b[0;36mgrade\u001b[0;34m(self, question, global_env)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# inspect trick to pass in its parents' global env.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mglobal_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;31m# We display the output if we're in IPython.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# This keeps backwards compatibility with okpy's grade method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/okgrade/grader.py\u001b[0m in \u001b[0;36mgrade\u001b[0;34m(test_file_path, global_env)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mTestResult\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_ok_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mglobal_env\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Get the global env of our callers - one level below us in the stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/okgrade/grader.py\u001b[0m in \u001b[0;36mparse_ok_test\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Do not support point values other than 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtest_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtest_suite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'suites'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_ = ok.grade(\"q1_1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 1.1.2\n",
    "Assign `stemmed_message` to the stemmed version of the word \"message\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'messag'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set stemmed_message to the stemmed version of \"message\" (which\n",
    "# should be a string).  Use vocab_table.\n",
    "stemmed_message = vocab_table.where(1, 'message').column(0)[0]\n",
    "stemmed_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>/Users/huangweijun/Desktop/cs/data8/project/project3/tests/q1_1_2.py: All tests passed!</pre>"
      ],
      "text/plain": [
       "<okgrade.result.TestResult at 0x12e266438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ok.grade(\"q1_1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 1.1.3\n",
    "Assign `unstemmed_singl` to the word in `vocab_table` that has \"singl\" as its stemmed form. (*Note that multiple English words may stem to \"singl\", but only one example appears in `vocab_table`.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'single'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set unstemmed_singl to the unstemmed version of \"singl\" (which\n",
    "# should be a string).\n",
    "unstemmed_singl = vocab_table.where(0, 'singl').column(1)[0]\n",
    "unstemmed_singl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-c32eb436040b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q1_1_3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/client/api/notebook.py\u001b[0m in \u001b[0;36mgrade\u001b[0;34m(self, question, global_env)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# inspect trick to pass in its parents' global env.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mglobal_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;31m# We display the output if we're in IPython.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# This keeps backwards compatibility with okpy's grade method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/okgrade/grader.py\u001b[0m in \u001b[0;36mgrade\u001b[0;34m(test_file_path, global_env)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mTestResult\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_ok_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mglobal_env\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Get the global env of our callers - one level below us in the stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/okgrade/grader.py\u001b[0m in \u001b[0;36mparse_ok_test\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Do not support point values other than 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtest_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtest_suite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'suites'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_ = ok.grade(\"q1_1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 1.1.4\n",
    "What word in `vocab_table` was shortened the most by this stemming process? Assign `most_shortened` to the word. It's an example of how heuristic stemming can collapse two unrelated words into the same stem (which is bad, but happens a lot in practice anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "for_assignment_type": "student",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Word</th> <th>count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>&     </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>'bout </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>'cause</td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>'cos  </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>'em   </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>'fore </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>'til  </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>(2x)  </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>(3x)  </td> <td>1    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>(4x)  </td> <td>1    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (4807 rows omitted)</p>"
      ],
      "text/plain": [
       "Word   | count\n",
       "&      | 1\n",
       "'bout  | 1\n",
       "'cause | 1\n",
       "'cos   | 1\n",
       "'em    | 1\n",
       "'fore  | 1\n",
       "'til   | 1\n",
       "(2x)   | 1\n",
       "(3x)   | 1\n",
       "(4x)   | 1\n",
       "... (4807 rows omitted)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In our solution, we found it useful to first make an array\n",
    "# called shortened containing the number of characters that was\n",
    "# chopped off of each word in vocab_table, but you don't have\n",
    "# to do that.\n",
    "shortened = vocab_table.group(1)\n",
    "most_shortened = ...\n",
    "# This will display your answer and its shortened form.\n",
    "vocab_table.where('Word', most_shortened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-bf4aeaaebdf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q1_1_4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/client/api/notebook.py\u001b[0m in \u001b[0;36mgrade\u001b[0;34m(self, question, global_env)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# inspect trick to pass in its parents' global env.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mglobal_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;31m# We display the output if we're in IPython.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# This keeps backwards compatibility with okpy's grade method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/okgrade/grader.py\u001b[0m in \u001b[0;36mgrade\u001b[0;34m(test_file_path, global_env)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mTestResult\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_ok_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mglobal_env\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Get the global env of our callers - one level below us in the stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/huangweijun/anaconda/envs/cs188/lib/python3.6/site-packages/okgrade/grader.py\u001b[0m in \u001b[0;36mparse_ok_test\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Do not support point values other than 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtest_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtest_suite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'suites'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_ = ok.grade(\"q1_1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.2. Splitting the dataset\n",
    "We're going to use our `lyrics` dataset for two purposes.\n",
    "\n",
    "1. First, we want to *train* song genre classifiers.\n",
    "2. Second, we want to *test* the performance of our classifiers.\n",
    "\n",
    "Hence, we need two different datasets: *training* and *test*.\n",
    "\n",
    "The purpose of a classifier is to classify unseen data that is similar to the training data. Therefore, we must ensure that there are no songs that appear in both sets. We do so by splitting the dataset randomly. The dataset has already been permuted randomly, so it's easy to split.  We just take the top for training and the rest for test. \n",
    "\n",
    "Run the code below (without changing it) to separate the datasets into two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  1183 ; Test:  538\n"
     ]
    }
   ],
   "source": [
    "# Here we have defined the proportion of our data\n",
    "# that we want to designate for training as 11/16ths\n",
    "# of our total dataset.  5/16ths of the data is\n",
    "# reserved for testing.\n",
    "\n",
    "training_proportion = 11/16\n",
    "\n",
    "num_songs = lyrics.num_rows\n",
    "num_train = int(num_songs * training_proportion)\n",
    "num_valid = num_songs - num_train\n",
    "\n",
    "train_lyrics = lyrics.take(np.arange(num_train))\n",
    "test_lyrics = lyrics.take(np.arange(num_train, num_songs))\n",
    "\n",
    "print(\"Training: \",   train_lyrics.num_rows, \";\",\n",
    "      \"Test: \",       test_lyrics.num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 1.2.1\n",
    "Draw a horizontal bar chart with two bars that show the proportion of Country songs in each dataset.  Complete the function `country_proportion` first; it should help you create the bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "for_assignment_type": "student",
    "jupyter": {
     "outputs_hidden": false
    },
    "manual_problem_id": "music_1_2_1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def country_proportion(table):\n",
    "    \"\"\"Return the proportion of songs in a table that have the Country genre.\"\"\"\n",
    "    return table.where('Genre', 'Country').num_rows/table.num_rows\n",
    "\n",
    "# The staff solution took 4 lines.  Start by creating a table.\n",
    "Table().with_columns(\n",
    "        'Dataset', make_array('Training', 'Test'),\n",
    "        'Proportion of Country', make_array(country_proportion(train_lyrics), country_proportion(test_lyrics)))\\\n",
    "        .barh('Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Checkpoint Reached\n",
    "\n",
    "You have reached the project checkpoint. Please submit now in order to record your progress. If you go back and revise your answers in the section above after the checkpoint is due, that's ok. Your revised answers will be graded. However, you will only get credit for your checkpoint submission if you have passed the tests provided for every question above.\n",
    "\n",
    "If you are working with a partner, only one of you needs to submit. For both of you to receive credit, the person who submits must invite the other to be their partner on [okpy.org](http://okpy.org). Please invite your partner now and tell them to accept the invitation **before** the checkpoint deadline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. K-Nearest Neighbors - a Guided Example\n",
    "\n",
    "K-Nearest Neighbors (k-NN) is a classification algorithm.  Given some *attributes* (also called *features*) of an unseen example, it decides whether that example belongs to one or the other of two categories based on its similarity to previously seen examples. Predicting the category of an example is called *labeling*, and the predicted category is also called a *label*.\n",
    "\n",
    "An attribute (feature) we have about each song is *the proportion of times a particular word appears in the lyrics*, and the labels are two music genres: hip-hop and country.  The algorithm requires many previously seen examples for which both the attributes and labels are known: that's the `train_lyrics` table.\n",
    "\n",
    "To build understanding, we're going to visualize the algorithm instead of just describing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.1. Classifying a  song\n",
    "\n",
    "In k-NN, we classify a song by finding the `k` songs in the *training set* that are most similar according to the features we choose. We call those songs with similar features the *nearest neighbors*.  The k-NN algorithm assigns the song to the most common category among its `k` nearest neighbors.\n",
    "\n",
    "Let's limit ourselves to just 2 features for now, so we can plot each song.  The features we will use are the proportions of the words \"like\" and \"love\" in the lyrics.  Taking the song \"In Your Eyes\" (in the test set), 0.0119 of its words are \"like\" and 0.0595 are \"love\". This song appears in the test set, so let's imagine that we don't yet know its genre.\n",
    "\n",
    "First, we need to make our notion of similarity more precise.  We will say that the *distance* between two songs is the straight-line distance between them when we plot their features in a scatter diagram. This distance is called the Euclidean (\"yoo-KLID-ee-un\") distance.  \n",
    "\n",
    "For example, in the song *Insane in the Brain* (in the training set), 0.0203 of all the words in the song are \"like\" and 0 are \"love\".  Its distance from *In Your Eyes* on this 2-word feature set is $\\sqrt{(0.0119 - 0.0203)^2 + (0.0595 - 0)^2} \\approx 0.06$.  (If we included more or different features, the distance could be different.)\n",
    "\n",
    "A third song, *Sangria Wine* (in the training set), is 0.0044 \"like\" and 0.0925 \"love\".\n",
    "\n",
    "The function below creates a plot to display the \"like\" and \"love\" features of a test song and some training songs. As you can see in the result, *In Your Eyes* is more similar to *Sangria Wine* than to *Insane in the Brain*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Just run this cell.\n",
    "\n",
    "def plot_with_two_features(test_song, training_songs, x_feature, y_feature):\n",
    "    \"\"\"Plot a test song and training songs using two features.\"\"\"\n",
    "    test_row = row_for_title(test_song)\n",
    "    distances = Table().with_columns(\n",
    "            x_feature, [test_row.item(x_feature)],\n",
    "            y_feature, [test_row.item(y_feature)],\n",
    "            'Color',   ['Unknown'],\n",
    "            'Title',   [test_song]\n",
    "        )\n",
    "    for song in training_songs:\n",
    "        row = row_for_title(song)\n",
    "        distances.append([row.item(x_feature), row.item(y_feature), row.item('Genre'), song])\n",
    "    distances.scatter(x_feature, y_feature, colors='Color', labels='Title', s=200)\n",
    "    \n",
    "training = [\"Sangria Wine\", \"Insane In The Brain\"]\n",
    "plot_with_two_features(\"In Your Eyes\", training, \"like\", \"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 2.1.1\n",
    "Compute the distance between the two country songs, *In Your Eyes* and *Sangria Wine*, using the `like` and `love` features only.  Assign it the name `country_distance`.\n",
    "\n",
    "**Note:** If you have a row object, you can use `item` to get a value from a column by its name.  For example, if `r` is a row, then `r.item(\"Genre\")` is the value in column `\"Genre\"` in row `r`.\n",
    "\n",
    "**Note 2:** You can quickly get the row from the `lyrics` table via `row_for_title`. For example, if \"Insane In The Brain\" is the song title, then `row_for_title(\"Insane In The Brain\")` is the row object for this song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "in_your_eyes = row_for_title(\"In Your Eyes\")\n",
    "sangria_wine = row_for_title(\"Sangria Wine\")\n",
    "country_distance = ...\n",
    "country_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q2_1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The `plot_with_two_features` function can show the positions of several training songs. Below, we've added one that's even closer to *In Your Eyes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training = [\"Sangria Wine\", \"Lookin' for Love\", \"Insane In The Brain\"]\n",
    "plot_with_two_features(\"In Your Eyes\", training, \"like\", \"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 2.1.2\n",
    "Complete the function `distance_two_features` that computes the Euclidean distance between any two songs, using two features. The last two lines call your function to show that *Lookin' for Love* is closer to *In Your Eyes* than *Insane In The Brain*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def distance_two_features(title0, title1, x_feature, y_feature):\n",
    "    \"\"\"Compute the distance between two songs with titles title0 and title1\n",
    "    \n",
    "    Only the features named x_feature and y_feature are used when computing the distance.\n",
    "    \"\"\"\n",
    "    row0 = ...\n",
    "    row1 = ...\n",
    "    ...\n",
    "\n",
    "for song in make_array(\"Lookin' for Love\", \"Insane In The Brain\"):\n",
    "    song_distance = distance_two_features(song, \"In Your Eyes\", \"like\", \"love\")\n",
    "    print(song, 'distance:\\t', song_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q2_1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 2.1.3\n",
    "Define the function `distance_from_in_your_eyes` so that it works as described in its documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def distance_from_in_your_eyes(title):\n",
    "    \"\"\"The distance between the given song and \"In Your Eyes\", based on the features \"like\" and \"love\".\n",
    "    \n",
    "    This function takes a single argument:\n",
    "      title: A string, the name of a song.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q2_1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 2.1.4\n",
    "Using the features `\"like\" and \"love\"`, what are the names and genres of the 7 songs in the **training set** closest to \"In Your Eyes\"?  To answer this question, make a table named `close_songs` containing those 7 songs with columns `\"Title\"`, `\"Artist\"`, `\"Genre\"`, `\"like\"`, and `\"love\"`, as well as a column called `\"distance\"` that contains the distance from \"In Your Eyes\".  The table should be **sorted in ascending order by `distance`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "for_assignment_type": "student",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The staff solution took 4 lines.\n",
    "close_songs = ...\n",
    "close_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q2_1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 2.1.5\n",
    "Define the function `most_common` so that it works as described in its documentation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def most_common(label, table):\n",
    "    \"\"\"The most common element in a column of a table.\n",
    "    \n",
    "    This function takes two arguments:\n",
    "      label: The label of a column, a string.\n",
    "      table: A table.\n",
    "     \n",
    "    It returns the most common value in that column of that table.\n",
    "    In case of a tie, it returns any one of the most common values\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "# Calling most_common on your table of 7 nearest neighbors classifies\n",
    "# \"In Your Eyes\" as a country song, 4 votes to 3.\n",
    "most_common('Genre', close_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q2_1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Congratulations are in order -- you've classified your first song!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we're going to extend our classifier to consider more than two features at a time.\n",
    "\n",
    "Euclidean distance still makes sense with more than two features. For `n` different features, we compute the difference between corresponding feature values for two songs, square each of the `n`  differences, sum up the resulting numbers, and take the square root of the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 3.1\n",
    "Write a function to compute the Euclidean distance between two *arrays* of features of *arbitrary* (but equal) length.  Use it to compute the distance between the first song in the training set and the first song in the test set, *using all of the features*.  (Remember that the title, artist, and genre of the songs are not features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def distance(features1, features2):\n",
    "    \"\"\"The Euclidean distance between two arrays of feature values.\"\"\"\n",
    "    ...\n",
    "\n",
    "distance_first_to_first = ...\n",
    "distance_first_to_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.1. Creating your own feature set\n",
    "\n",
    "Unfortunately, using all of the features has some downsides.  One clear downside is *computational* -- computing Euclidean distances just takes a long time when we have lots of features.  You might have noticed that in the last question!\n",
    "\n",
    "So we're going to select just 20.  We'd like to choose features that are very *discriminative*. That is, features which lead us to correctly classify as much of the test set as possible.  This process of choosing features that will make a classifier work well is sometimes called *feature selection*, or more broadly *feature engineering*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 3.1.1\n",
    "Look through the list of features (the labels of the `lyrics` table after the first three).  Choose 20 common words that you think might let you distinguish between country and hip-hop songs. Make sure to choose words that are frequent enough that every song contains at least one of them. Don't just choose the 20 most frequent, though... you can do much better.\n",
    "\n",
    "You might want to come back to this question later to improve your list, once you've seen how to evaluate your classifier.  The first time you answer this question, spend some time looking through the features, but not more than 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set my_20_features to an array of 20 features (strings that are column labels)\n",
    "my_20_features = ...\n",
    "\n",
    "train_20 = train_lyrics.select(my_20_features)\n",
    "test_20 = test_lyrics.select(my_20_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This test makes sure that you have chosen words such that at least one appears in each song. If you can't find words that satisfy this test just through intuition, try writing code to print out the titles of songs that do not contain any words from your list, then look at the words they do contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q3_1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 3.1.2\n",
    "In two sentences or less, describe how you selected your features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "manual_problem_id": "music_3_1_2"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, let's classify the first song from our test set using these features.  You can examine the song by running the cells below. Do you think it will be classified correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Song:\")\n",
    "test_lyrics.take(0).select('Title', 'Artist', 'Genre').show()\n",
    "print(\"Features:\")\n",
    "test_20.take(0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As before, we want to look for the songs in the training set that are most alike our test song.  We will calculate the Euclidean distances from the test song (using the 20 selected features) to all songs in the training set.  You could do this with a `for` loop, but to make it computationally faster, we have provided a function, `fast_distances`, to do this for you.  Read its documentation to make sure you understand what it does.  (You don't need to read the code in its body unless you want to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Just run this cell to define fast_distances.\n",
    "\n",
    "def fast_distances(test_row, train_rows):\n",
    "    \"\"\"An array of the distances between test_row and each row in train_rows.\n",
    "\n",
    "    Takes 2 arguments:\n",
    "      test_row: A row of a table containing features of one\n",
    "        test song (e.g., test_20.row(0)).\n",
    "      train_rows: A table of features (for example, the whole\n",
    "        table train_20).\"\"\"\n",
    "    assert train_rows.num_columns < 50, \"Make sure you're not using all the features of the lyrics table.\"\n",
    "    counts_matrix = np.asmatrix(train_rows.columns).transpose()\n",
    "    diff = np.tile(np.array(test_row), [counts_matrix.shape[0], 1]) - counts_matrix\n",
    "    distances = np.squeeze(np.asarray(np.sqrt(np.square(diff).sum(1))))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 3.1.3\n",
    "Use the `fast_distances` function provided above to compute the distance from the first song in the test set to all the songs in the training set, **using your set of 20 features**.  Make a new table called `genre_and_distances` with one row for each song in the training set and two columns:\n",
    "* The `\"Genre\"` of the training song\n",
    "* The `\"Distance\"` from the first song in the test set \n",
    "\n",
    "Ensure that `genre_and_distances` is **sorted in increasing order by distance to the first test song**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "for_assignment_type": "student",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The staff solution took 4 lines of code.\n",
    "genre_and_distances = ...\n",
    "genre_and_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q3_1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 3.1.4\n",
    "Now compute the 5-nearest neighbors classification of the first song in the test set.  That is, decide on its genre by finding the most common genre among its 5 nearest neighbors, according to the distances you've calculated.  Then check whether your classifier chose the right genre.  (Depending on the features you chose, your classifier might not get this song right, and that's okay.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set my_assigned_genre to the most common genre among these.\n",
    "my_assigned_genre = ...\n",
    "\n",
    "# Set my_assigned_genre_was_correct to True if my_assigned_genre\n",
    "# matches the actual genre of the first song in the test set.\n",
    "my_assigned_genre_was_correct = ...\n",
    "\n",
    "print(\"The assigned genre, {}, was{}correct.\".format(my_assigned_genre, \" \" if my_assigned_genre_was_correct else \" not \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q3_1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.2. A classifier function\n",
    "\n",
    "Now we can write a single function that encapsulates the whole process of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 3.2.1\n",
    "Write a function called `classify`.  It should take the following four arguments:\n",
    "* A row of features for a song to classify (e.g., `test_20.row(0)`).\n",
    "* A table with a column for each feature (for example, `train_20`).\n",
    "* An array of classes that has as many items as the previous table has rows, and in the same order.\n",
    "* `k`, the number of neighbors to use in classification.\n",
    "\n",
    "It should return the class a `k`-nearest neighbor classifier picks for the given row of features (the string `'Country'` or the string `'Hip-hop'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def classify(test_row, train_rows, train_classes, k):\n",
    "    \"\"\"Return the most common class among k nearest neigbors to test_row.\"\"\"\n",
    "    distances = fast_distances(test_row, train_rows)\n",
    "    genre_and_distances = ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q3_2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 3.2.2\n",
    "Assign `grandpa_genre` to the genre predicted by your classifier for the song \"Grandpa Got Runned Over By A John Deere\" in the test set, using **9 neighbors** and using your 20 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The staff solution first defined a row object called grandpa_features.\n",
    "grandpa_features = ...\n",
    "grandpa_genre = ...\n",
    "grandpa_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q3_2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, when we evaluate our classifier, it will be useful to have a classification function that is specialized to use a fixed training set and a fixed value of `k`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 3.2.3\n",
    "Create a classification function that takes as its argument a row containing your 20 features and classifies that row using the 5-nearest neighbors algorithm with `train_20` as its training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def classify_one_argument(row):\n",
    "    ...\n",
    "\n",
    "# When you're done, this should produce 'Hip-hop' or 'Country'.\n",
    "classify_one_argument(test_20.row(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q3_2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.3. Evaluating your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that it's easy to use the classifier, let's see how accurate it is on the whole test set.\n",
    "\n",
    "**Question 3.3.1.** Use `classify_one_argument` and `apply` to classify every song in the test set.  Name these guesses `test_guesses`.  **Then**, compute the proportion of correct classifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_guesses = ...\n",
    "proportion_correct = ...\n",
    "proportion_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q3_3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "At this point, you've gone through one cycle of classifier design.  Let's summarize the steps:\n",
    "1. From available data, select test and training sets.\n",
    "2. Choose an algorithm you're going to use for classification.\n",
    "3. Identify some features.\n",
    "4. Define a classifier function using your features and the training set.\n",
    "5. Evaluate its performance (the proportion of correct classifications) on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Extra Explorations\n",
    "Now that you know how to evaluate a classifier, it's time to build a better one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Question 4.1\n",
    "Find a classifier with better test-set accuracy than `classify_one_argument`.  (Your new function should have the same arguments as `classify_one_argument` and return a classification.  Name it `another_classifier`.)  You can use more or different features, or you can try different values of `k`.  (Of course, you still have to use `train_lyrics` as your training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# To start you off, here's a list of possibly-useful features:\n",
    "staff_features = make_array(\"come\", \"do\", \"have\", \"heart\", \"make\", \"never\", \"now\", \"wanna\", \"with\", \"yo\")\n",
    "\n",
    "train_staff = train_lyrics.select(staff_features)\n",
    "test_staff = test_lyrics.select(staff_features)\n",
    "\n",
    "def another_classifier(row):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Briefly describe what you tried to improve your classifier. As long as you put in some effort to improving your classifier and describe what you have done, you will receive full credit for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "manual_problem_id": "music_4_1"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Congratulations: you're done with the required portion of the project! Time to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ungraded and Optional: A Custom Classifier\n",
    "Try to create an even better classifier. You're not restricted to using only word proportions as features.  For example, given the data, you could compute various notions of vocabulary size or estimated song length.  If you're feeling very adventurous, you could also try other classification methods, like logistic regression.  If you think you built a classifier that works well, post on Piazza and let us know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "# Custom Classifier #\n",
    "#####################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Kaggle Competition\n",
    "\n",
    "**Note:** This part is completely optional and will not contribute towards your grade in any way.\n",
    "\n",
    "We decided to *hold out* a set of 100 songs, for which we have provided the attributes but not the genres. You can use this set to evaluate how well you classifier performs on data for which you have never seen the correct genres. Optionally, you can submit your predictions on this dataset to Kaggle to compare your classifier to others (whoever else decides to participate).\n",
    "\n",
    "To participate, use your classifier to predict the genre of each row in the `holdout` table. Then, call ```create_competition_submission``` to generate a CSV file that you can submit to the competition!\n",
    "\n",
    "If you want to participate in the competition, you will have to create a Kaggle account. It's easiest for the staff to determine the winners of the competition if you use your `@berkeley.edu` email when doing so, but you can also contact your GSI if you decide to use another email address. Winners may receive honor and glory, but no material benefit.\n",
    "\n",
    "When you are ready to make a submission, go to https://inclass.kaggle.com/c/hip-hop-or-country for further instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "holdout = Table.read_table('holdout_attributes.csv').drop('Id')\n",
    "holdout.select(0, 1, 2, 3, 4).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_competition_submission(predictions, filename='my_submission.csv'):\n",
    "    \"\"\"\n",
    "    Create a submission CSV for the Kaggle competition.\n",
    "    \n",
    "    Inputs:\n",
    "      predictions - list or array of your predictions (Generated as in Question 3.3.1.)\n",
    "    \"\"\"\n",
    "    Table().with_columns('Id', np.arange(len(predictions)), 'Predictions', predictions).to_csv(filename)\n",
    "    print('Created', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here's an example of how to generate a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "create_competition_submission(holdout.select(*my_20_features).apply(classify_one_argument))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q')]\n",
    "print(\"Finished running all tests.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
